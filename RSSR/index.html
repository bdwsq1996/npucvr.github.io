<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Inverting a Rolling Shutter Camera: Bring Rolling Shutter Images to High Framerate Global Shutter Video</title>
  <!-- Bootstrap -->
  <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <!-- <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script> -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
</head>

<!-- cover -->
<section>
  <div class="jumbotron text-center mt-0">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2>Inverting a Rolling Shutter Camera: Bring Rolling Shutter Images to High Framerate Global Shutter Video</h2>
          <!-- <h4 style="color:#5a6268;">On submission</h4> -->
          <h4 style="color:#5a6268;">ICCV 2021</h4>
          <hr>
          <h6>
            <a href="https://gitcvfb.github.io/" target="_blank">Bin Fan</a>,
            <a href="https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl=en" target="_blank">Yuchao Dai</a>
          </h6>
          <p>School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China &nbsp;&nbsp;
          </p>

          <div class="row justify-content-center">
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Fan_Inverting_a_Rolling_Shutter_Camera_Bring_Rolling_Shutter_Images_to_ICCV_2021_paper.pdf" role="button" target="">
                  <i class="fa fa-file"></i> Paper </a> </p>
            </div>
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/GitCVfb/RSSR" role="button" target="">
                  <i class="fa fa-github-alt"></i> Code </a> </p>
            </div>
            <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://mp.weixin.qq.com/s?__biz=MzUxMDE4MzAzOA==&mid=2247545670&idx=1&sn=a53f5068f42972b6ad685c755dac9e51&chksm=f904a057ce7329413608af236d57c3a4885714e493a5fa7fcb317fa08583454e6e77ac97e3f5&mpshare=1&scene=2&srcid=1122fsFHf50niSNoPy5TMrAZ&sharer_sharetime=1637573708969&sharer_shareid=e129ba814f278ac058b97c4a7ef575f9&from=timeline&isappinstalled=0&clicktime=1655030780&enterid=1655030780&ascene=45&devicetype=iOS14.8&version=18001726&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&fontScale=100&exportkey=AZSMK346onWh5yFmRi5U9kQ%3D&pass_ticket=SgzC0uJc%2FnwMn%2BEAwzef4ceVsg5IDNRx1t95XycaSTm3dwPmigr6FsggvjXir%2Bws&wx_header=3" role="button" target="">
                  <i class="fa fa-database"></i> CSIG 成果速览 </a> </p>
            </div>
	    <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://ieeexplore.ieee.org/document/9926197/keywords#keywords" role="button" target="">
                  <i class="fa fa-database"></i> TPAMI 2022 拓展版本 </a> </p>
            </div>
            <!-- <div class="column">
              <p class="mb-5"><a class="btn btn-large btn-light" href="https://xxx" role="button">
                  <i class="fa fa-file"></i> Supplementary </a> </p>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- abstract -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Abstract</h3>
        <hr style="margin-top:0px">
        <p class="text-left">Rolling shutter (RS) images can be viewed as the result of the row-wise combination of global shutter (GS) images captured by a virtual moving GS camera over the period of camera readout time. The RS effect brings tremendous difficulties for the downstream applications.
          In this paper, we propose to invert the above RS imaging mechanism, i.e., recovering a high framerate GS video from consecutive RS images to achieve RS temporal super-resolution (RSSR).
          This extremely challenging problem, e.g., recovering 1440 GS images from two 720-height RS images, is far from being solved end-to-end.
          To address this challenge, we exploit the geometric constraint in the RS camera model, thus achieving geometry-aware inversion.
          Specifically, we make three contributions in resolving the above difficulties: 
          (i) formulating the bidirectional RS undistortion flows under the constant velocity motion model,
          (ii) building the connection between the RS undistortion flow and optical flow via a scaling operation, and 
          (iii) developing a mutual conversion scheme between varying RS undistortion flows that correspond to different scanlines.
          Building upon these formulations, we propose the first RS temporal super-resolution network in a cascaded structure to extract high framerate global shutter video. 
          Our method explores the underlying spatio-temporal geometric relationships within a deep learning framework, where no extra supervision besides the middle-scanline ground truth GS image is needed. Essentially, our method can be very efficient for explicit propagation to generate GS images under any scanline.
          Experimental results on both synthetic and real data show that our method can produce high-quality GS image sequences with rich details, outperforming state-of-the-art methods. </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- contribution -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Contribution</h3>
        <hr style="margin-top:0px">
          <ul class="text-left">
            <li>We identify and establish a detailed proof of the scanline-dependent nature of the bidirectional RS undistortion flows, which is essential for understanding the intrinsic geometrical properties of RS correction problem.</li>
            <li>From the theoretical perspective, we provide a sound motivation for our first learning-based RSSR solution for latent GS video sequence extraction from two consecutive RS images, which brings RS images alive.</li>
            <li>Our approach not only outperforms the state-of-the-art methods in both RS effect removal and inference efficiency, but also can produce a smooth and continuous video sequence far beyond the reach of the existing method.</li>
          </ul>
        </div>
    </div>
  </div>
</section>
<br>

<!-- showcase -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Problem Statement</h3>
        <hr style="margin-top:0px">
          <img class="img-fluid" width="85%" src="images/Problem_statement.jpg" alt="Architecture">
        <p class="text-left"> The RS image is generated by continuously synthesizing the GS image row by row, while our rolling shutter temporal super-resolution (RSSR) pipeline reverses this process, 
          i.e., extracting the latent GS image sequence from two consecutive RS images.</p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- overview video -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Overview Video</h3>
        <hr style="margin-top:0px">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe width="950" height="534" src="https://www.youtube.com/embed/X8cQf8uLDHw" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>
<br>

<!-- showcase -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Network Architecture</h3>
        <hr style="margin-top:0px">
          <img class="img-fluid" width="60%" src="images/Network_framework.jpg" alt="Architecture">
        <p class="text-left"> Given two input consecutive RS frames, we first estimate the bidirectional optical flows. 
          Then, we use the UNet architecture to resolve the correlation maps. Next, the middle-scanline RS undistortion flows can be calculated explicitly, while being certifiable. 
          Finally, we adopt softmax splatting to generate the target middle-scanline GS frames. 
          Note that our main network is designed to predict the latent GS images corresponding to the middle scanline during training. 
          In particular, in the test phase, the RS undistortion flows for any scanline $s\in[0,h-1]$ can be propagated explicitly (see dashed arrow), followed by the recovery of the GS image corresponding to scanline $s$.</p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- demo video -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Demo Video</h3>
        <hr style="margin-top:0px">
        <div class="embed-responsive embed-responsive-16by9">
          <iframe width="950" height="534" src="https://www.youtube.com/embed/nNSInzPF9yI" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>
<br>


<!-- 
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Demo Video</h3>
        <hr style="margin-top:0px">
        <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
          <source src="./videos/RSSR_Video.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
<br>
-->


<!-- Flows -->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>RS Undistortion Flow vs. Optical Flow</h3>
        <hr style="margin-top:0px">
        <img class="img-fluid" width="95%" src="images/Various_flows.jpg" alt="ablation study">
        <p class="text-left"> 
          Compared to the isotropically smooth regular optical flow map, the RS undistortion flow map exhibits a more significant scanline dependence. On the one hand, the RS undistortion flows near the target scanline appear as lighter colors (i.e., smaller warping displacement values). 
          On the other hand, the RS undistortion flows corresponding to pixels smaller than and larger than the target scanline show different colors (i.e., different warping displacement directions).
        </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- Qualitative comparison-->
<section>
  <div class="container">
    <div class="row">
      <div class="col-12 text-center">
        <h3>Qualitative Comparison</h3>
        <hr style="margin-top:0px">
        <img class="img-fluid" width="95%" src="images/Qualitative_comparison.jpg" alt="ablation study">
        <p class="text-left"> 
          Visual comparisons on Fastec-RS testing set. We zoom in the correction results according to the blue boxes. While other methods cause various artifacts, our method produces best results.
        </p>
      </div>
    </div>
  </div>
</section>
<br>

<!-- citing -->
<div class="container">
  <div class="row ">
    <div class="col-12">
      <h3>Citation</h3>
      <hr style="margin-top:0px">
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@inproceedings{fan_RSSR_ICCV21,
  title={Inverting a rolling shutter camera: bring rolling shutter images to high framerate global shutter video},
  author={Fan, Bin and Dai, Yuchao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4228--4237},
  year={2021}
}
</code></pre>
      <hr>
      <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{fan_RSSR_PAMI22,
	title={Rolling shutter inversion: bring rolling shutter images to high framerate global shutter video},
	author={Fan, Bin and Dai, Yuchao and Li, Hongdong},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2022},
	volume={},
	number={},
	pages={},
	publisher={IEEE}
}
</code></pre>
    </div>
  </div>
</div>

<footer class="text-center" style="margin-bottom:10px">
  <br>
  Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the website template.
</footer>

</body>

</html>
